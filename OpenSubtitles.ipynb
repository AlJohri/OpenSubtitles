{
 "metadata": {
  "name": "",
  "signature": "sha256:6fa3c882cda090762218c263257204e4923cf964ac17466fceab3ce126261421"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All imports."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "import logging, sys, random\n",
      "from time import time\n",
      "\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import Normalizer\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import pairwise_distances\n",
      "\n",
      "import numpy as np\n",
      "from scipy.stats import mode\n",
      "import matplotlib.pyplot as plt, mpld3\n",
      "from mpld3 import plugins\n",
      "# mpld3.enable_notebook()\n",
      "\n",
      "def find_movie(os_id):\n",
      "    return filter(lambda movie: movie['osID'] == str(os_id), movies)\n",
      "\n",
      "def make_histogram(innerDict):\n",
      "    x = np.arange(len(innerDict.keys()))\n",
      "    y = innerDict.values()\n",
      "    fig = plt.figure(figsize=(20,10))\n",
      "    ax = fig.add_subplot(1,1,1)\n",
      "    ax.bar(x, y)\n",
      "    ax.set_xticks(x)\n",
      "    ax.set_xticklabels(innerDict.keys(), rotation=70)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Movie Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from load import movies\n",
      "movies = np.array(movies)\n",
      "print (\"loaded data\")\n",
      "\n",
      "genres = set()\n",
      "for movie in movies:\n",
      "    for genre in movie.get('Genre', []):\n",
      "        genres.add(genre)\n",
      "genres = list(genres)\n",
      "\n",
      "print genres"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded data\n",
        "[u'Sci-Fi', u'Crime', u'Romance', u'Animation', u'Music', u'Comedy', u'War', u'Horror', u'Adult', u'News', u'Western', u'Thriller', u'Adventure', u'Mystery', u'Short', u'Talk-Show', u'N/A', u'Drama', u'Action', u'Documentary', u'Musical', u'History', u'Family', u'Fantasy', u'Sport', u'Biography']\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N_CLUSTERS = 3\n",
      "reduce_dimensionality = True\n",
      "k_means = KMeans(n_clusters=N_CLUSTERS, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
      "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
      "lsa = TruncatedSVD(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = [movie['script'] for movie in movies]\n",
      "vectors = vectorizer.fit_transform(text)\n",
      "if reduce_dimensionality == True:\n",
      "    X = lsa.fit_transform(vectors)\n",
      "else:\n",
      "    X = vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-27-cd86b841b742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmovie\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduce_dimensionality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/atul/.pyenv/versions/2.7.8/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \"\"\"\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/atul/.pyenv/versions/2.7.8/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/atul/.pyenv/versions/2.7.8/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                     \u001b[0;31m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km = k_means.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_means_labels = k_means.labels_\n",
      "k_means_cluster_centers = k_means.cluster_centers_\n",
      "k_means_labels_unique = np.unique(k_means_labels)\n",
      "terms = vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if reduce_dimensionality == False:\n",
      "    order_centroids = k_means_cluster_centers.argsort()[:, ::-1]\n",
      "    for i in range(N_CLUSTERS):\n",
      "        print [(terms[ind], k_means_cluster_centers[i][ind]) for ind in order_centroids[i, :100]]\n",
      "        print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in range(N_CLUSTERS):\n",
      "    z = vectors.toarray()[k_means_labels == k]\n",
      "    wordz_tfidf = [(terms[i], z[:,i].sum()) for i in range(z.shape[1])]\n",
      "    wordz_tfidf = sorted(wordz_tfidf, key=lambda x: x[1], reverse=True )\n",
      "    print wordz_tfidf[:100]\n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if reduce_dimensionality == True:\n",
      "    mpld3.enable_notebook()\n",
      "    fig,ax = plt.subplots(figsize=(15,10)) #.figure(figsize=(20,10))\n",
      "#     ax = fig.add_subplot(1,1,1)\n",
      "#     ax.grid(True, alpha=0.3)\n",
      "\n",
      "    colors = [(random.random(), random.random(), random.random()) for x in range(N_CLUSTERS)]\n",
      "    for k, col in zip(range(N_CLUSTERS), colors):\n",
      "        my_members = k_means_labels == k\n",
      "        cluster_center = k_means_cluster_centers[k]\n",
      "        points = ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.', label='Cluster %i' % k)\n",
      "        centers = ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
      "        \n",
      "        labels = []\n",
      "        for movie in movies[k_means_labels == k]:\n",
      "            labels.append(movie.get('Title', '') + \" \" + movie.get('osID', '') + \" \" + movie.get('imdbID', '') + \" \" + \", \".join(movie.get('Genre', '')) + \" \" + movie.get('', '') + \" \")\n",
      "\n",
      "        tooltip = plugins.PointHTMLTooltip(points[0], labels, voffset=10, hoffset=10)\n",
      "        plugins.connect(fig, tooltip)\n",
      "\n",
      "    ax.set_title('KMeans')\n",
      "    ax.set_xticks(())\n",
      "    ax.set_yticks(())\n",
      "    ax.legend()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mpld3.disable_notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "find_movie(3909)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_histogram = []\n",
      "for k in range(N_CLUSTERS):\n",
      "    innerDict = dict.fromkeys(genres, 0)\n",
      "    for movie in movies[k_means_labels == k]:\n",
      "        genres = movie.get('Genre', '')\n",
      "        for genre in genres:\n",
      "            if genre in innerDict:\n",
      "                innerDict[genre] = innerDict[genre]+1\n",
      "            else:\n",
      "                innerDict[genre] = 0\n",
      "\n",
      "    genre_histogram.append(innerDict)\n",
      "genre_histogram"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year_histogram = []\n",
      "for k in range(N_CLUSTERS):\n",
      "    innerDict = {}\n",
      "    for movie in movies[k_means_labels == k]:\n",
      "        year = movie.get('Year', '')\n",
      "        if year in innerDict:\n",
      "            innerDict[year] = innerDict[year]+1\n",
      "        else:\n",
      "            innerDict[year] = 0\n",
      "    year_histogram.append(innerDict)\n",
      "year_histogram"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "make_histogram(genre_histogram[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "make_histogram(genre_histogram[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "make_histogram(genre_histogram[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}